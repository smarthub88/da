# Demonstrate data cleaning - missing values

library(tidyverse)
x <- sample(1:21, 20, replace = TRUE)  
y <- sample(1:10, 20, replace = TRUE) 
for(i in 1:20) { 
  a <- x[i] 
  b <- y[i] 
  mtcars[a, b] = NA 
} 
which(is.na(mtcars)) 
sum(is.na(mtcars)) 
# Permanently remove rows with NA values in mtcars
mtcars <- na.exclude(mtcars)
view(mtcars)  # Now mtcars will display without rows containing NA values
dispna <- apply(mtcars["disp"], 2, mean, na.rm=TRUE) 
view(dispna) 
newcars <- mtcars %>% 
  mutate(disp = ifelse(is.na(disp), dispna, disp))
view(newcars)

-------------------------------------------------------
#Implement data normalization (min-max, z-score)
arr <- c(9.5, 6.2, 8.9, 15.2, 20.0, 10.1, 5.4, 3.2, 1.0, 22.5, 10.0, 16.0) 
#min-max 
minarr <- min(arr) 
maxarr <- max(arr) 
arr2 <- arr 
for (i in 1:12){ 
  arr2[i] = round((arr[i]-minarr)/(maxarr-minarr),2) 
} 
print(arr2) 


------------------------------------------------------------
#Implement data normalization (min-max, z-score)
meanarr <- mean(arr) 
sdarr <- sd(arr) 

# Perform Z-score Normalization
for (i in 1:12) { 
  arr2[i] <- round((arr[i] - meanarr) / sdarr,2) 
} 

print(arr2)
--------------------------------------------------------------
# Implement attribute subset selection for data reduction


library(tidyverse)  # For data manipulation
library(leaps)      # For regsubsets

# Convert Titanic to a data.frame if necessary
Titanic <- as.data.frame(Titanic)

# View dataset and check for missing values
view(Titanic)  # Use `head(Titanic)` if `view()` does not work in your environment
sum(is.na(Titanic))

# Remove any rows with NA values (if any)
Titanic <- Titanic %>% na.omit()

# Check dimensions
dim(Titanic)

# Perform subset selection
fwd <- regsubsets(Freq ~ ., data = Titanic, nvmax = 19, method = "forward")
bwd <- regsubsets(Freq ~ ., data = Titanic, nvmax = 19, method = "backward")
full <- regsubsets(Freq ~ ., data = Titanic, nvmax = 19)

# Summarize results
summary(fwd)
summary(bwd)
summary(full)

# Get coefficients for models with 3 predictors
coef(fwd, 3)
coef(bwd, 3)
coef(full, 3)

------------------------------------------------------------------------
#Demonstrate outlier detection
# Set seed for reproducibility
library(tidyr)

set.seed(123)

# Create a sample dataset
day <- data.frame(
  temp = rnorm(100, mean = 20, sd = 5),       # Random temperatures
  hum = rnorm(100, mean = 60, sd = 10),        # Random humidity percentages
  windspeed = rnorm(100, mean = 10, sd = 3)    # Random wind speeds
)

# Add some outliers
day$temp[c(10, 20, 30)] <- c(40, 45, 50)      # Adding extreme temperatures
day$hum[c(15, 25, 35)] <- c(10, 5, 0)         # Adding extreme humidity values
day$windspeed[c(40, 50, 60)] <- c(25, 30, 35) # Adding extreme wind speeds

# Add some missing values
day$temp[c(5, 15)] <- NA
day$hum[c(10, 20)] <- NA
day$windspeed[c(30, 40)] <- NA

sum(is.na(day))
boxplot(day[,c("temp","hum","windspeed")])

for(i in c("hum","windspeed"))
{
  data<-unlist(day[i])
  newData<-data[data %in% boxplot.stats(data)$out]
  data[data %in% newData]<-NA
  day[i]<-data
}

sum(is.na(data))
day<-na.exclude(day)
boxplot(day[,c("temp","hum","windspeed")])



-------------------------------------------------------------------------
#Perform analytics on any standard data set  4*4*3*3(3)*1(3)*1(3)*3(3)*1(2) Load necessary libraries
library(tidyverse)
library(titanic)

# Load the titanic_train dataset from the titanic package
data("titanic_train")

# View the first few rows of the dataset
head(titanic_train)

# Check the class of each column
sapply(titanic_train, class)

# Convert 'Sex' and 'Survived' columns to factors
titanic_train$Sex = as.factor(titanic_train$Sex)
titanic_train$Survived = as.factor(titanic_train$Survived)

# Summary of the dataset
summary(titanic_train)

# Remove rows with missing values
dropnull_titanic = titanic_train[rowSums(is.na(titanic_train)) <= 0, ]

# Filter passengers who survived and who did not survive
survivedList = dropnull_titanic[dropnull_titanic$Survived == 1 , ]
notSurvivedList = dropnull_titanic[dropnull_titanic$Survived == 0, ]

# Create a table for the 'Survived' column
mytable <- table(titanic_train$Survived)

# Create labels for the pie chart
lbls <- paste(names(titanic_train), "\n", mytable, sep = "")

# Plot a pie chart for the 'Survived' column
pie(mytable, labels = lbls, main = "Pie chart")

# Create a histogram for the 'Age' column
hist(titanic_train$Age, xlab = "Age", ylab = "Frequency")

# Create a bar plot for the 'notSurvivedList Sex' column for passengers who did not survive
barplot(table(notSurvivedList$Sex), xlab = "Sex", ylab = "Frequency")

# Create a density plot for the ' survivedList Fare' column of passengers who survived
temp <- density(table(survivedList$Fare))
plot(temp, type = "n", main = "Fare Charged")
polygon(temp, col = "lightgray", border = "gray")

# Create a boxplot for the 'Fare' column
boxplot(titanic_train$Fare, main = "Fare")

------------------------------------------------------------
# Load necessary libraries 2*4*3*2*4
library(caTools)
library(ggplot2)

# Create the data frame
data <- data.frame( 
  Years_Exp = c(1.1, 1.3, 1.5, 2.0, 2.2, 2.9, 3.0, 3.2, 3.2, 3.7), 
  Salary = c(39343.00, 46205.00, 37731.00, 43525.00, 39891.00, 56642.00, 60150.00, 54445.00, 64445.00, 57189.00) 
)

# Split the data into training and testing sets
split = sample.split(data$Salary, SplitRatio = 0.7)
train = subset(data, split == TRUE)
test = subset(data, split == FALSE)

# Fit the linear regression model
lm.r = lm(formula = Salary ~ Years_Exp, data = train)

# Display the coefficients of the model
coef(lm.r)

# Visualize the data and the regression line
ggplot() + 
  geom_point(aes(x = train$Years_Exp, y = train$Salary), col = 'red') + 
  geom_line(aes(x = train$Years_Exp, y = predict(lm.r, data = train)), col = "blue") +
  ggtitle("Salary vs Experience")

--------------------------------------------------------------------------------------------
#4*5*2*2*1*2*4*9
library(tidyverse)
library(ROCR)
library(caTools)
library(ggplot2)

# Split the data
split <- sample.split(mtcars$vs, SplitRatio = 0.8)
train <- subset(mtcars, split == TRUE)
test <- subset(mtcars, split == FALSE)
train <- na.omit(train)
test <- na.omit(test)

# Logistic regression model
logistic_model <- glm(vs ~ wt + disp, data = train, family = binomial)
summary(logistic_model)

# Predictions
predict_reg <- predict(logistic_model, test, type = "response")
predict_reg <- ifelse(predict_reg > 0.5, 1, 0)

# Confusion matrix
table(test$vs, predict_reg)

# Calculate classification error and accuracy
missing_classerr <- mean(predict_reg != test$vs)
print(paste("accuracy = ", (1 - missing_classerr)))

# Logistic regression curve plot
ggplot(mtcars, aes(x = wt, y = vs)) +  
  geom_point(alpha = .5) + 
  stat_smooth(method = "glm", se = FALSE, method.args = list(family = binomial), 
              col = "red")

# ROC curve and AUC calculation
ROCPred = prediction(predict_reg, test$vs)
ROCPer = performance(ROCPred, measure = "tpr", x.measure = "fpr")
auc <- performance(ROCPred, measure = "auc")
auc <- auc@y.values[[1]]
auc
plot(ROCPer, colorize = TRUE, print.cutoffs.at = seq(0.1, by = 0.1), main = "ROC Curve")
abline(a = 0, b = 1)
auc <- round(auc, 4)
legend(.6, .4, auc, title = "AUC", cex = 1)

-----------------------------------------------------------------------------
library(partykit)
library(caTools)

# Set seed for reproducibility
set.seed(123)

# Create a sample weather dataset with some correlation
weatherdata <- data.frame(
  Temperature = rnorm(200, mean = 20, sd = 5),       # Random temperatures around 20 degrees
  Humidity = rnorm(200, mean = 75, sd = 10),         # Random humidity percentages around 75%
  WindSpeed = rnorm(200, mean = 10, sd = 3),         # Random wind speeds around 10 km/h
  RainToday = sample(c("Yes", "No"), 200, replace = TRUE)  # Random yes/no for rain today
)

# Create the dependent variable 'weather' with some dependency on Humidity and Temperature
weatherdata$weather <- with(weatherdata, ifelse(Humidity > 70 & Temperature < 22, "Yes", "No"))

# Convert 'weather' to a factor
weatherdata$weather <- as.factor(weatherdata$weather)
weatherdata$RainToday<-as.factor(weatherdata$RainToday)

# Split the data into training and testing sets
split <- sample.split(weatherdata$weather, SplitRatio = 0.8)
train <- subset(weatherdata, split == TRUE)
test <- subset(weatherdata, split == FALSE)

# Fit the decision tree model
model <- ctree(weather ~ RainToday+Temperature + Humidity + WindSpeed, data = train)
plot(model)

# Make predictions on the test set
predict_model <- predict(model, test)

mat <- table(test$weather, predict_model)
print(mat)

accuracy <- sum(diag(mat)) / sum(mat)
print(paste("Accuracy:", accuracy))



---------------------------------------------------------------
#2*2*1(3)*1(4)*1(3)*2*1(5)*3*3
positiveCases <- c(580, 7813, 28266, 59287, 75700, 87820, 95314, 126214, 
                   218843, 471497, 936851, 1508725, 2072113)

deaths <- c(17, 270, 565, 1261, 2126, 2800, 3285, 4628, 8951, 21283, 47210, 
            88480, 138475)

library(lubridate)
library(forecast)

# Create the multivariate time series object
mts <- ts(cbind(positiveCases, deaths), 
          start = decimal_date(ymd("2020-01-22")), 
          frequency = 365.25 / 7)

# Plot the multivariate time series (without saving)
plot(mts, xlab ="Weekly Data", 
     main ="COVID-19 Cases (Positive vs Deaths)", 
     col.main ="darkgreen")

# Time series for positive cases alone
mts1 <- ts(positiveCases, decimal_date(ymd("2020-01-22")), frequency = 365.25 / 7)

# Fit ARIMA model and forecast
fit <- auto.arima(mts1)
forecast_result <- forecast(fit, 5)

# Plot the forecast (without saving)
plot(forecast_result, xlab="Weekly Data", ylab = "Positive Cases", 
     main = "COVID-19 Positive Cases Forecast", col.main = "green")

# Save the multivariate time series plot
png(file="multivariateTimeSeries.png")
plot(mts, xlab ="Weekly Data", 
     main ="COVID-19 Cases (Positive vs Deaths)", 
     col.main ="darkgreen")
dev.off()  # Close the graphical device

# Save the forecast plot
png(file = "timeseries.png")
plot(forecast_result, xlab="Weekly Data", ylab = "Positive Cases", 
     main = "COVID-19 Positive Cases Forecast", col.main = "green")
dev.off()  # Close the graphical device

------------------------------------------------------------------------------
# Load the airquality dataset 1*3(4)*2(6)*2(2)*2(6)*4(3)
data(airquality)

# 1. Barplot for Ozone Concentration
# Remove NA values for ozone concentration
ozone_clean <- na.omit(airquality$Ozone)
# Create a table of the frequencies of each ozone concentration level
ozone_table <- table(ozone_clean)
# Create the barplot using the table
barplot(ozone_table,main = 'Ozone Concentration in Air',xlab = 'Ozone Levels', horiz = TRUE)

# 2. Histogram for Temperature
# Remove NA values for temperature
temp_clean <- na.omit(airquality$Temp)
hist(temp_clean, main = "La Guardia Airport's Maximum Temperature (Daily)", xlab = "Temperature (Fahrenheit)", xlim = c(50, 125), col = "yellow", freq = TRUE)

# 3. Boxplot for Air Quality Parameters (Ozone, Temp, Wind, and Solar.R)
# Handle NA values for each parameter
airquality_clean <- na.omit(airquality[, c("Ozone", "Temp", "Wind", "Solar.R")])
boxplot(airquality_clean, main = 'Box Plots for Air Quality Parameters')

# 4. Scatter Plot of Ozone vs Month
# Remove NA values for Ozone and Month
ozone_month_clean <- na.omit(airquality[, c("Ozone", "Month")])
plot(ozone_month_clean$Ozone, ozone_month_clean$Month,main = "Scatterplot Example",xlab = "Ozone Concentration (ppb)",ylab = "Month of Observation", pch = 19)

# 5. Heatmap for Randomly Generated Data
data <- matrix(rnorm(50, 0, 5), nrow = 5, ncol = 5)
# Set column and row names
colnames(data) <- paste0("col", 1:5)
rownames(data) <- paste0("row", 1:5)
# Draw a heatmap
heatmap(data, main = "Heatmap of Random Data", col = heat.colors(256))

